#!/usr/bin/env python3
import sys
import os
import argparse
import numpy as np
import torch
import gymnasium as gym
import cv2
from pathlib import Path

# --- 1. ç¯å¢ƒè·¯å¾„è®¾ç½® ---
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# --- 2. å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---
import src.envs
from src.models.custom_model import make_vizdoom_actor_critic
from src.envs.vizdoom_env import create_vizdoom_env

# --- 3. PyTorch å®‰å…¨è¡¥ä¸ ---
import numpy.dtypes
torch.serialization.add_safe_globals([
    np.core.multiarray.scalar, 
    np.dtype, 
    np.dtypes.Float64DType, 
    np.dtypes.Int64DType
])

# --- 4. è¾…åŠ©ç±» ---
class AttrDict(dict):
    __getattr__ = dict.__getitem__
    __setattr__ = dict.__setitem__

class DictObservationWrapper(gym.ObservationWrapper):
    """
    å°† Box è§‚å¯Ÿç©ºé—´åŒ…è£…ä¸º Dict è§‚å¯Ÿç©ºé—´ï¼Œé€‚é… Sample Factoryã€‚
    """
    def __init__(self, env):
        super().__init__(env)
        self.observation_space = gym.spaces.Dict({
            "obs": env.observation_space
        })
    
    def observation(self, obs):
        return {"obs": obs}

def get_eval_config(args):
    """
    æ„é€ ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„é…ç½®å¯¹è±¡ã€‚
    """
    return AttrDict(
        # æ ¸å¿ƒæ¨¡å‹å‚æ•°
        use_rnn=True,
        rnn_size=512,
        rnn_type='gru',
        actor_critic_share_weights=True,
        
        # è¡¥å…¨ç¼ºå¤±çš„ Decoder å‚æ•°
        decoder_mlp_layers=[512],  # Sample Factory é»˜è®¤é€šå¸¸æ˜¯ [512]
        
        # ç¯å¢ƒé…ç½®
        res_w=128,
        res_h=72,
        wide_aspect_ratio=False,
        env_frameskip=4,
        pixel_format='CHW',
        
        # å½’ä¸€åŒ–å‚æ•° (Sample Factory ActorCritic åˆå§‹åŒ–å¿…éœ€)
        normalize_input=True,
        normalize_input_keys=None,
        obs_subtract_mean=0.0,
        obs_scale=255.0,
        normalize_returns=True,
        
        # è¡¥å…¨å…¶ä»–å¯èƒ½éœ€è¦çš„é»˜è®¤å‚æ•°
        nonlinearity='relu',
        use_encoder_linear=True,
    )

def main():
    parser = argparse.ArgumentParser(description="VizDoom Evaluation Script (Whitebox)")
    parser.add_argument("--checkpoint", type=str, required=True, help="Path to .pth file")
    parser.add_argument("--env", type=str, default="custom_doom_health_gathering", help="Env name")
    parser.add_argument("--episodes", type=int, default=3, help="Number of episodes")
    parser.add_argument("--video-dir", type=str, default="final_videos", help="Output folder")
    parser.add_argument("--device", type=str, default="cpu", help="cpu or cuda")
    
    args = parser.parse_args()
    device = torch.device(args.device)
    cfg = get_eval_config(args)

    print(f"\nğŸ¬ === Starting Evaluation ===")
    print(f"   Env:        {args.env}")
    print(f"   Checkpoint: {args.checkpoint}")
    print(f"   Device:     {device}")
    
    # 1. åˆ›å»ºç¯å¢ƒ
    print("   Creating environment...")
    try:
        raw_env = create_vizdoom_env(args.env, cfg=cfg, render_mode='rgb_array')
    except Exception as e:
        print(f"âš ï¸  Env creation fallback: {e}")
        raw_env = create_vizdoom_env(args.env, render_mode='rgb_array')

    # 2. åŒ…è£… Dict ç©ºé—´
    if not isinstance(raw_env.observation_space, gym.spaces.Dict):
        print("   Wrapping environment in DictObservationWrapper...")
        raw_env = DictObservationWrapper(raw_env)

    # 3. å‡†å¤‡è§†é¢‘ä¿å­˜è·¯å¾„
    env = raw_env
    video_path = os.path.abspath(args.video_dir)
    os.makedirs(video_path, exist_ok=True)
    
    print(f"   Obs Space: {env.observation_space}")
    print(f"   Act Space: {env.action_space}")

    # 4. åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ§  Initializing model architecture...")
    model = make_vizdoom_actor_critic(cfg, env.observation_space, env.action_space)
    model.to(device)
    model.eval()

    # 5. åŠ è½½æƒé‡
    print("ğŸ“¥ Loading weights...")
    try:
        checkpoint = torch.load(args.checkpoint, map_location=device, weights_only=False)
        state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint
        model.load_state_dict(state_dict, strict=False)
        print("âœ… Weights loaded.")
    except Exception as e:
        print(f"âŒ Error loading weights: {e}")
        sys.exit(1)

    # 6. è¯„ä¼°å¾ªç¯
    print("\nğŸš€ Starting Run Loop...")
    rewards = []
    
    for i in range(args.episodes):
        obs, info = env.reset()
        done = False
        ep_reward = 0.0
        step = 0
        
        # å‡†å¤‡è§†é¢‘å†™å…¥å™¨
        video_name = os.path.join(video_path, f"{args.env}-ep{i}.mp4")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = None

        # åˆå§‹åŒ– RNN (Batch=1)
        rnn_states = torch.zeros(1, cfg.rnn_size, device=device)

        while not done:
            # æ•è·å½“å‰ç”»é¢
            frame = env.render()
            if frame is not None:
                if video_writer is None:
                    h, w, _ = frame.shape
                    video_writer = cv2.VideoWriter(video_name, fourcc, 30, (w, h))
                # ViZDoom è¿”å› RGBï¼ŒOpenCV éœ€è¦ BGR
                video_writer.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))

            step += 1
            
            # æ•°æ®é¢„å¤„ç†
            if isinstance(obs, dict):
                obs_data = obs['obs']
            else:
                obs_data = obs
            
            # è½¬ä¸º Tensor [1, 1, 84, 84]
            obs_tensor = torch.from_numpy(obs_data).float().to(device).unsqueeze(0)
            obs_dict = {'obs': obs_tensor}

            # æ¨ç†
            with torch.no_grad():
                result = model(obs_dict, rnn_states, values_only=False)
            
            # å…¼å®¹ä¸åŒçš„ Key è¿”å›
            action_logits = result.get('action_logits', result.get('logits'))
            rnn_states = result['new_rnn_states']
            
            # åŠ¨ä½œé‡‡æ ·
            dist = torch.distributions.Categorical(logits=action_logits)
            action = dist.sample().item()
            
            # æ­¥è¿›
            obs, r, terminated, truncated, info = env.step(action)
            ep_reward += r
            done = terminated or truncated

        if video_writer:
            video_writer.release()
        rewards.append(ep_reward)
        print(f"   Episode {i+1}: Reward = {ep_reward:.2f}, Steps = {step}")

    env.close()
    print(f"\nğŸ“Š Result: Average Reward = {np.mean(rewards):.2f}")
    print(f"ğŸ’¾ Videos saved at: {video_path}")

if __name__ == "__main__":
    main()